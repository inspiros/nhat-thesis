%!TEX root = ../../main.tex

\section{Accomplishments}
    In this thesis, we have presented a novel framework for human action recognition. Our proposed framework integrates various successful deep features with multi-view discriminant analysis to deal with cross-view human action recognition. In this work, five deep models have been utilized: ResNet with three pooling techniques; ResNet-3D and C3D. These deep features have been universally used for action recognition from a common view but rarely utilized for evaluating cross-view HAR. Besides, three variations of Multi-view Discriminant Analysis: the original MvDA, MvDA with view consistency (MvDA-vc) and our proposed pairwise-covariance MvDA (pc-MvDA) have been investigated. MvDA has been successfully deployed for cross-view recognition of static images but never applied for spatio-temporal features. Our experiments show that our proposed pc-MvDA technique achieved highest average accuracy (5.29\% higher than MvDA and 1.21\% higher than MvDA-vc). In addition, ResNet-50 3D gives the best overall HAR accuracy for both cross-view and multi-view evaluation protocols. It concludes that the combination of deep features with pc-MvDA is suitable and feasible to deploy the proposed framework in practical applications. 
